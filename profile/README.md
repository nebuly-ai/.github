## What is NebulyAI?

At [Nebuly](https://www.nebuly.com/), we view Large Language Models (LLMs) not merely as a new computing platform but as a transformative user experience revolution. As LLMs transition from proof of concept (PoC) to production, it’s essential for companies to ensure they provide real value to users.

This is where Nebuly comes in. We empower product and AI teams to comprehend and enhance the user experience of LLM-based products. By analyzing user behavior and interactions with LLMs, we create detailed user profiles to identify what works well and what needs improvement, ensuring an optimal experience for the end user.

### Useful links

- To learn more on how to get started, visit our [official documentation](https://docs.nebuly.com/welcome/overview)
- If you need enterprise support, please contact us [here](https://www.nebuly.com/nebuly-book-a-demo)

### Community projects
We have open-sourced a couple of internal projects to the community, but we are not currently maintaining them:
- Nos: If you have limited GPU resources and want to maximize GPU utilization for your LLMs, this module is designed to help you achieve that.
- Optimate: If you’re looking to optimize the latency and cost of your LLMs, this library allows you to automatically apply multiple optimization techniques.
